{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3l3r_-Y7ZCQt",
        "outputId": "cfe82353-004c-43ab-dfcf-7dd11dc34d59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install grad-cam"
      ],
      "metadata": {
        "id": "EmLjFpTFZXY5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9bb6a4d-24e5-42d2-f3de-66e48da27ebc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting grad-cam\n",
            "  Using cached grad-cam-1.5.4.tar.gz (7.8 MB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from grad-cam) (1.26.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from grad-cam) (11.0.0)\n",
            "Requirement already satisfied: torch>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from grad-cam) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.10/dist-packages (from grad-cam) (0.20.1+cu121)\n",
            "Collecting ttach (from grad-cam)\n",
            "  Downloading ttach-0.0.3-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from grad-cam) (4.67.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from grad-cam) (4.10.0.84)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from grad-cam) (3.8.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from grad-cam) (1.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->grad-cam) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->grad-cam) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->grad-cam) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->grad-cam) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->grad-cam) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->grad-cam) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.7.1->grad-cam) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->grad-cam) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->grad-cam) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->grad-cam) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->grad-cam) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->grad-cam) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->grad-cam) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->grad-cam) (2.8.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->grad-cam) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->grad-cam) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->grad-cam) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->grad-cam) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7.1->grad-cam) (3.0.2)\n",
            "Downloading ttach-0.0.3-py3-none-any.whl (9.8 kB)\n",
            "Building wheels for collected packages: grad-cam\n",
            "  Building wheel for grad-cam (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for grad-cam: filename=grad_cam-1.5.4-py3-none-any.whl size=39648 sha256=afd171562d8aaa7dbccc27fd07b98859b740b08b451a34dc513a9ef0932717ec\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/b0/82/1f97b5348c7fe9f0ce0ba18497202cafa5dec4562bd5292680\n",
            "Successfully built grad-cam\n",
            "Installing collected packages: ttach, grad-cam\n",
            "Successfully installed grad-cam-1.5.4 ttach-0.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade grad-cam"
      ],
      "metadata": {
        "id": "jMEh4AeKZbul",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed092266-7620-49fe-ce25-22e7121cde23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: grad-cam in /usr/local/lib/python3.10/dist-packages (1.5.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from grad-cam) (1.26.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from grad-cam) (11.0.0)\n",
            "Requirement already satisfied: torch>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from grad-cam) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.10/dist-packages (from grad-cam) (0.20.1+cu121)\n",
            "Requirement already satisfied: ttach in /usr/local/lib/python3.10/dist-packages (from grad-cam) (0.0.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from grad-cam) (4.67.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from grad-cam) (4.10.0.84)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from grad-cam) (3.8.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from grad-cam) (1.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->grad-cam) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->grad-cam) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->grad-cam) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->grad-cam) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->grad-cam) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->grad-cam) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.7.1->grad-cam) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->grad-cam) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->grad-cam) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->grad-cam) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->grad-cam) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->grad-cam) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->grad-cam) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->grad-cam) (2.8.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->grad-cam) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->grad-cam) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->grad-cam) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->grad-cam) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7.1->grad-cam) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tarfile\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from pytorch_grad_cam import GradCAM\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
        "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "ryFcktZPZdM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tar_path = r'/content/drive/MyDrive/CSE366/1/101_ObjectCategories.tar.gz'\n",
        "extract_path = r'/content/drive/MyDrive/CSE366/2/101_ObjectCategories'\n",
        "\n",
        "# Extract the dataset\n",
        "if not os.path.exists(extract_path):\n",
        "    with tarfile.open(tar_path, 'r:gz') as tar:\n",
        "        tar.extractall(path=os.path.dirname(extract_path))\n",
        "    print(\"Extraction complete.\")\n",
        "else:\n",
        "    print(\"Dataset already extracted.\")\n",
        "\n",
        "# Path to the dataset\n",
        "root_dir = extract_path"
      ],
      "metadata": {
        "id": "7OYolzBdZfxb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae5b63cd-df5e-4088-e24d-10d5ac52a0d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extraction complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect the dataset structure\n",
        "classes = os.listdir(root_dir)\n",
        "print(f\"Found {len(classes)} classes: {classes[:5]}...\")\n"
      ],
      "metadata": {
        "id": "sEshmNocZ8Z-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db377d27-fa1d-4b4a-c295-be7e2e5e8152"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 102 classes: ['BACKGROUND_Google', 'Faces', 'Faces_easy', 'Leopards', 'Motorbikes']...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure no unexpected folders are included\n",
        "if 'BACKGROUND_Google' in classes:\n",
        "    print(\"Excluding 'BACKGROUND_Google' class.\")\n",
        "    classes.remove('BACKGROUND_Google')"
      ],
      "metadata": {
        "id": "DFtjgwNEZ-3k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4418442c-f083-45f0-e7fc-a471010e6335"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Excluding 'BACKGROUND_Google' class.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.RandomRotation(30),\n",
        "    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),\n",
        "    transforms.RandomAffine(degrees=15, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
        "    transforms.RandomGrayscale(p=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "MJtC9KQWaCW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "for root, _, files in os.walk(root_dir):\n",
        "    for file in files:\n",
        "        try:\n",
        "            img_path = os.path.join(root, file)\n",
        "            with Image.open(img_path) as img:\n",
        "                img.verify()  # Verify if it's a valid image\n",
        "        except Exception as e:\n",
        "            print(f\"Invalid file: {img_path}, Error: {e}\")"
      ],
      "metadata": {
        "id": "Ks_R7zxMaFu-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "dataset = datasets.ImageFolder(root=root_dir, transform=transform)\n",
        "\n",
        "# Verify class mappings\n",
        "print(f\"Class-to-index mapping: {dataset.class_to_idx}\")\n",
        "\n",
        "# Split dataset\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = int(0.1 * len(dataset))\n",
        "test_size = len(dataset) - train_size - val_size\n",
        "train_data, val_data, test_data = random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "# Data loaders\n",
        "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=32)\n",
        "test_loader = DataLoader(test_data, batch_size=32)"
      ],
      "metadata": {
        "id": "d4s_qoNoaH5y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "116db34a-7257-4e7b-c198-86f5fa41f512"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class-to-index mapping: {'BACKGROUND_Google': 0, 'Faces': 1, 'Faces_easy': 2, 'Leopards': 3, 'Motorbikes': 4, 'accordion': 5, 'airplanes': 6, 'anchor': 7, 'ant': 8, 'barrel': 9, 'bass': 10, 'beaver': 11, 'binocular': 12, 'bonsai': 13, 'brain': 14, 'brontosaurus': 15, 'buddha': 16, 'butterfly': 17, 'camera': 18, 'cannon': 19, 'car_side': 20, 'ceiling_fan': 21, 'cellphone': 22, 'chair': 23, 'chandelier': 24, 'cougar_body': 25, 'cougar_face': 26, 'crab': 27, 'crayfish': 28, 'crocodile': 29, 'crocodile_head': 30, 'cup': 31, 'dalmatian': 32, 'dollar_bill': 33, 'dolphin': 34, 'dragonfly': 35, 'electric_guitar': 36, 'elephant': 37, 'emu': 38, 'euphonium': 39, 'ewer': 40, 'ferry': 41, 'flamingo': 42, 'flamingo_head': 43, 'garfield': 44, 'gerenuk': 45, 'gramophone': 46, 'grand_piano': 47, 'hawksbill': 48, 'headphone': 49, 'hedgehog': 50, 'helicopter': 51, 'ibis': 52, 'inline_skate': 53, 'joshua_tree': 54, 'kangaroo': 55, 'ketch': 56, 'lamp': 57, 'laptop': 58, 'llama': 59, 'lobster': 60, 'lotus': 61, 'mandolin': 62, 'mayfly': 63, 'menorah': 64, 'metronome': 65, 'minaret': 66, 'nautilus': 67, 'octopus': 68, 'okapi': 69, 'pagoda': 70, 'panda': 71, 'pigeon': 72, 'pizza': 73, 'platypus': 74, 'pyramid': 75, 'revolver': 76, 'rhino': 77, 'rooster': 78, 'saxophone': 79, 'schooner': 80, 'scissors': 81, 'scorpion': 82, 'sea_horse': 83, 'snoopy': 84, 'soccer_ball': 85, 'stapler': 86, 'starfish': 87, 'stegosaurus': 88, 'stop_sign': 89, 'strawberry': 90, 'sunflower': 91, 'tick': 92, 'trilobite': 93, 'umbrella': 94, 'watch': 95, 'water_lilly': 96, 'wheelchair': 97, 'wild_cat': 98, 'windsor_chair': 99, 'wrench': 100, 'yin_yang': 101}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Model Selection\n",
        "# Adjust model for correct number of classes\n",
        "num_classes = len(dataset.classes)\n",
        "model = models.resnet50(pretrained=True)\n",
        "model.fc = nn.Linear(model.fc.in_features, num_classes)  # Adjust for detected classes\n"
      ],
      "metadata": {
        "id": "GaN9656LaJyM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20b3f104-97f5-4f57-f24a-ab1a949199de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 128MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Training\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "\n",
        "for epoch in range(10):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
        "        print(f\"Processing batch {batch_idx + 1}/{len(train_loader)}\")\n",
        "        try:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "        except Exception as e:\n",
        "            print(f\"Skipping problematic batch: {e}\")\n",
        "            continue\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}, Loss: {train_loss / len(train_loader):.4f}\")\n"
      ],
      "metadata": {
        "id": "r2iga136aLXZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00854529-e736-4d32-b2ba-8a49181219f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing batch 1/229\n",
            "Processing batch 2/229\n",
            "Processing batch 3/229\n",
            "Processing batch 4/229\n",
            "Processing batch 5/229\n",
            "Processing batch 6/229\n",
            "Processing batch 7/229\n",
            "Processing batch 8/229\n",
            "Processing batch 9/229\n",
            "Processing batch 10/229\n",
            "Processing batch 11/229\n",
            "Processing batch 12/229\n",
            "Processing batch 13/229\n",
            "Processing batch 14/229\n",
            "Processing batch 15/229\n",
            "Processing batch 16/229\n",
            "Processing batch 17/229\n",
            "Processing batch 18/229\n",
            "Processing batch 19/229\n",
            "Processing batch 20/229\n",
            "Processing batch 21/229\n",
            "Processing batch 22/229\n",
            "Processing batch 23/229\n",
            "Processing batch 24/229\n",
            "Processing batch 25/229\n",
            "Processing batch 26/229\n",
            "Processing batch 27/229\n",
            "Processing batch 28/229\n",
            "Processing batch 29/229\n",
            "Processing batch 30/229\n",
            "Processing batch 31/229\n",
            "Processing batch 32/229\n",
            "Processing batch 33/229\n",
            "Processing batch 34/229\n",
            "Processing batch 35/229\n",
            "Processing batch 36/229\n",
            "Processing batch 37/229\n",
            "Processing batch 38/229\n",
            "Processing batch 39/229\n",
            "Processing batch 40/229\n",
            "Processing batch 41/229\n",
            "Processing batch 42/229\n",
            "Processing batch 43/229\n",
            "Processing batch 44/229\n",
            "Processing batch 45/229\n",
            "Processing batch 46/229\n",
            "Processing batch 47/229\n",
            "Processing batch 48/229\n",
            "Processing batch 49/229\n",
            "Processing batch 50/229\n",
            "Processing batch 51/229\n",
            "Processing batch 52/229\n",
            "Processing batch 53/229\n",
            "Processing batch 54/229\n",
            "Processing batch 55/229\n",
            "Processing batch 56/229\n",
            "Processing batch 57/229\n",
            "Processing batch 58/229\n",
            "Processing batch 59/229\n",
            "Processing batch 60/229\n",
            "Processing batch 61/229\n",
            "Processing batch 62/229\n",
            "Processing batch 63/229\n",
            "Processing batch 64/229\n",
            "Processing batch 65/229\n",
            "Processing batch 66/229\n",
            "Processing batch 67/229\n",
            "Processing batch 68/229\n",
            "Processing batch 69/229\n",
            "Processing batch 70/229\n",
            "Processing batch 71/229\n",
            "Processing batch 72/229\n",
            "Processing batch 73/229\n",
            "Processing batch 74/229\n",
            "Processing batch 75/229\n",
            "Processing batch 76/229\n",
            "Processing batch 77/229\n",
            "Processing batch 78/229\n",
            "Processing batch 79/229\n",
            "Processing batch 80/229\n",
            "Processing batch 81/229\n",
            "Processing batch 82/229\n",
            "Processing batch 83/229\n",
            "Processing batch 84/229\n",
            "Processing batch 85/229\n",
            "Processing batch 86/229\n",
            "Processing batch 87/229\n",
            "Processing batch 88/229\n",
            "Processing batch 89/229\n",
            "Processing batch 90/229\n",
            "Processing batch 91/229\n",
            "Processing batch 92/229\n",
            "Processing batch 93/229\n",
            "Processing batch 94/229\n",
            "Processing batch 95/229\n",
            "Processing batch 96/229\n",
            "Processing batch 97/229\n",
            "Processing batch 98/229\n",
            "Processing batch 99/229\n",
            "Processing batch 100/229\n",
            "Processing batch 101/229\n",
            "Processing batch 102/229\n",
            "Processing batch 103/229\n",
            "Processing batch 104/229\n",
            "Processing batch 105/229\n",
            "Processing batch 106/229\n",
            "Processing batch 107/229\n",
            "Processing batch 108/229\n",
            "Processing batch 109/229\n",
            "Processing batch 110/229\n",
            "Processing batch 111/229\n",
            "Processing batch 112/229\n",
            "Processing batch 113/229\n",
            "Processing batch 114/229\n",
            "Processing batch 115/229\n",
            "Processing batch 116/229\n",
            "Processing batch 117/229\n",
            "Processing batch 118/229\n",
            "Processing batch 119/229\n",
            "Processing batch 120/229\n",
            "Processing batch 121/229\n",
            "Processing batch 122/229\n",
            "Processing batch 123/229\n",
            "Processing batch 124/229\n",
            "Processing batch 125/229\n",
            "Processing batch 126/229\n",
            "Processing batch 127/229\n",
            "Processing batch 128/229\n",
            "Processing batch 129/229\n",
            "Processing batch 130/229\n",
            "Processing batch 131/229\n",
            "Processing batch 132/229\n",
            "Processing batch 133/229\n",
            "Processing batch 134/229\n",
            "Processing batch 135/229\n",
            "Processing batch 136/229\n",
            "Processing batch 137/229\n",
            "Processing batch 138/229\n",
            "Processing batch 139/229\n",
            "Processing batch 140/229\n",
            "Processing batch 141/229\n",
            "Processing batch 142/229\n",
            "Processing batch 143/229\n",
            "Processing batch 144/229\n",
            "Processing batch 145/229\n",
            "Processing batch 146/229\n",
            "Processing batch 147/229\n",
            "Processing batch 148/229\n",
            "Processing batch 149/229\n",
            "Processing batch 150/229\n",
            "Processing batch 151/229\n",
            "Processing batch 152/229\n",
            "Processing batch 153/229\n",
            "Processing batch 154/229\n",
            "Processing batch 155/229\n",
            "Processing batch 156/229\n",
            "Processing batch 157/229\n",
            "Processing batch 158/229\n",
            "Processing batch 159/229\n",
            "Processing batch 160/229\n",
            "Processing batch 161/229\n",
            "Processing batch 162/229\n",
            "Processing batch 163/229\n",
            "Processing batch 164/229\n",
            "Processing batch 165/229\n",
            "Processing batch 166/229\n",
            "Processing batch 167/229\n",
            "Processing batch 168/229\n",
            "Processing batch 169/229\n",
            "Processing batch 170/229\n",
            "Processing batch 171/229\n",
            "Processing batch 172/229\n",
            "Processing batch 173/229\n",
            "Processing batch 174/229\n",
            "Processing batch 175/229\n",
            "Processing batch 176/229\n",
            "Processing batch 177/229\n",
            "Processing batch 178/229\n",
            "Processing batch 179/229\n",
            "Processing batch 180/229\n",
            "Processing batch 181/229\n",
            "Processing batch 182/229\n",
            "Processing batch 183/229\n",
            "Processing batch 184/229\n",
            "Processing batch 185/229\n",
            "Processing batch 186/229\n",
            "Processing batch 187/229\n",
            "Processing batch 188/229\n",
            "Processing batch 189/229\n",
            "Processing batch 190/229\n",
            "Processing batch 191/229\n",
            "Processing batch 192/229\n",
            "Processing batch 193/229\n",
            "Processing batch 194/229\n",
            "Processing batch 195/229\n",
            "Processing batch 196/229\n",
            "Processing batch 197/229\n",
            "Processing batch 198/229\n",
            "Processing batch 199/229\n",
            "Processing batch 200/229\n",
            "Processing batch 201/229\n",
            "Processing batch 202/229\n",
            "Processing batch 203/229\n",
            "Processing batch 204/229\n",
            "Processing batch 205/229\n",
            "Processing batch 206/229\n",
            "Processing batch 207/229\n",
            "Processing batch 208/229\n",
            "Processing batch 209/229\n",
            "Processing batch 210/229\n",
            "Processing batch 211/229\n",
            "Processing batch 212/229\n",
            "Processing batch 213/229\n",
            "Processing batch 214/229\n",
            "Processing batch 215/229\n",
            "Processing batch 216/229\n",
            "Processing batch 217/229\n",
            "Processing batch 218/229\n",
            "Processing batch 219/229\n",
            "Processing batch 220/229\n",
            "Processing batch 221/229\n",
            "Processing batch 222/229\n",
            "Processing batch 223/229\n",
            "Processing batch 224/229\n",
            "Processing batch 225/229\n",
            "Processing batch 226/229\n",
            "Processing batch 227/229\n",
            "Processing batch 228/229\n",
            "Processing batch 229/229\n",
            "Epoch 1, Loss: 3.6582\n",
            "Processing batch 1/229\n",
            "Processing batch 2/229\n",
            "Processing batch 3/229\n",
            "Processing batch 4/229\n",
            "Processing batch 5/229\n",
            "Processing batch 6/229\n",
            "Processing batch 7/229\n",
            "Processing batch 8/229\n",
            "Processing batch 9/229\n",
            "Processing batch 10/229\n",
            "Processing batch 11/229\n",
            "Processing batch 12/229\n",
            "Processing batch 13/229\n",
            "Processing batch 14/229\n",
            "Processing batch 15/229\n",
            "Processing batch 16/229\n",
            "Processing batch 17/229\n",
            "Processing batch 18/229\n",
            "Processing batch 19/229\n",
            "Processing batch 20/229\n",
            "Processing batch 21/229\n",
            "Processing batch 22/229\n",
            "Processing batch 23/229\n",
            "Processing batch 24/229\n",
            "Processing batch 25/229\n",
            "Processing batch 26/229\n",
            "Processing batch 27/229\n",
            "Processing batch 28/229\n",
            "Processing batch 29/229\n",
            "Processing batch 30/229\n",
            "Processing batch 31/229\n",
            "Processing batch 32/229\n",
            "Processing batch 33/229\n",
            "Processing batch 34/229\n",
            "Processing batch 35/229\n",
            "Processing batch 36/229\n",
            "Processing batch 37/229\n",
            "Processing batch 38/229\n",
            "Processing batch 39/229\n",
            "Processing batch 40/229\n",
            "Processing batch 41/229\n",
            "Processing batch 42/229\n",
            "Processing batch 43/229\n",
            "Processing batch 44/229\n",
            "Processing batch 45/229\n",
            "Processing batch 46/229\n",
            "Processing batch 47/229\n",
            "Processing batch 48/229\n",
            "Processing batch 49/229\n",
            "Processing batch 50/229\n",
            "Processing batch 51/229\n",
            "Processing batch 52/229\n",
            "Processing batch 53/229\n",
            "Processing batch 54/229\n",
            "Processing batch 55/229\n",
            "Processing batch 56/229\n",
            "Processing batch 57/229\n",
            "Processing batch 58/229\n",
            "Processing batch 59/229\n",
            "Processing batch 60/229\n",
            "Processing batch 61/229\n",
            "Processing batch 62/229\n",
            "Processing batch 63/229\n",
            "Processing batch 64/229\n",
            "Processing batch 65/229\n",
            "Processing batch 66/229\n",
            "Processing batch 67/229\n",
            "Processing batch 68/229\n",
            "Processing batch 69/229\n",
            "Processing batch 70/229\n",
            "Processing batch 71/229\n",
            "Processing batch 72/229\n",
            "Processing batch 73/229\n",
            "Processing batch 74/229\n",
            "Processing batch 75/229\n",
            "Processing batch 76/229\n",
            "Processing batch 77/229\n",
            "Processing batch 78/229\n",
            "Processing batch 79/229\n",
            "Processing batch 80/229\n",
            "Processing batch 81/229\n",
            "Processing batch 82/229\n",
            "Processing batch 83/229\n",
            "Processing batch 84/229\n",
            "Processing batch 85/229\n",
            "Processing batch 86/229\n",
            "Processing batch 87/229\n",
            "Processing batch 88/229\n",
            "Processing batch 89/229\n",
            "Processing batch 90/229\n",
            "Processing batch 91/229\n",
            "Processing batch 92/229\n",
            "Processing batch 93/229\n",
            "Processing batch 94/229\n",
            "Processing batch 95/229\n",
            "Processing batch 96/229\n",
            "Processing batch 97/229\n",
            "Processing batch 98/229\n",
            "Processing batch 99/229\n",
            "Processing batch 100/229\n",
            "Processing batch 101/229\n",
            "Processing batch 102/229\n",
            "Processing batch 103/229\n",
            "Processing batch 104/229\n",
            "Processing batch 105/229\n",
            "Processing batch 106/229\n",
            "Processing batch 107/229\n",
            "Processing batch 108/229\n",
            "Processing batch 109/229\n",
            "Processing batch 110/229\n",
            "Processing batch 111/229\n",
            "Processing batch 112/229\n",
            "Processing batch 113/229\n",
            "Processing batch 114/229\n",
            "Processing batch 115/229\n",
            "Processing batch 116/229\n",
            "Processing batch 117/229\n",
            "Processing batch 118/229\n",
            "Processing batch 119/229\n",
            "Processing batch 120/229\n",
            "Processing batch 121/229\n",
            "Processing batch 122/229\n",
            "Processing batch 123/229\n",
            "Processing batch 124/229\n",
            "Processing batch 125/229\n",
            "Processing batch 126/229\n",
            "Processing batch 127/229\n",
            "Processing batch 128/229\n",
            "Processing batch 129/229\n",
            "Processing batch 130/229\n",
            "Processing batch 131/229\n",
            "Processing batch 132/229\n",
            "Processing batch 133/229\n",
            "Processing batch 134/229\n",
            "Processing batch 135/229\n",
            "Processing batch 136/229\n",
            "Processing batch 137/229\n",
            "Processing batch 138/229\n",
            "Processing batch 139/229\n",
            "Processing batch 140/229\n",
            "Processing batch 141/229\n",
            "Processing batch 142/229\n",
            "Processing batch 143/229\n",
            "Processing batch 144/229\n",
            "Processing batch 145/229\n",
            "Processing batch 146/229\n",
            "Processing batch 147/229\n",
            "Processing batch 148/229\n",
            "Processing batch 149/229\n",
            "Processing batch 150/229\n",
            "Processing batch 151/229\n",
            "Processing batch 152/229\n",
            "Processing batch 153/229\n",
            "Processing batch 154/229\n",
            "Processing batch 155/229\n",
            "Processing batch 156/229\n",
            "Processing batch 157/229\n",
            "Processing batch 158/229\n",
            "Processing batch 159/229\n",
            "Processing batch 160/229\n",
            "Processing batch 161/229\n",
            "Processing batch 162/229\n",
            "Processing batch 163/229\n",
            "Processing batch 164/229\n",
            "Processing batch 165/229\n",
            "Processing batch 166/229\n",
            "Processing batch 167/229\n",
            "Processing batch 168/229\n",
            "Processing batch 169/229\n",
            "Processing batch 170/229\n",
            "Processing batch 171/229\n",
            "Processing batch 172/229\n",
            "Processing batch 173/229\n",
            "Processing batch 174/229\n",
            "Processing batch 175/229\n",
            "Processing batch 176/229\n",
            "Processing batch 177/229\n",
            "Processing batch 178/229\n",
            "Processing batch 179/229\n",
            "Processing batch 180/229\n",
            "Processing batch 181/229\n",
            "Processing batch 182/229\n",
            "Processing batch 183/229\n",
            "Processing batch 184/229\n",
            "Processing batch 185/229\n",
            "Processing batch 186/229\n",
            "Processing batch 187/229\n",
            "Processing batch 188/229\n",
            "Processing batch 189/229\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Validation\n",
        "model.eval()\n",
        "val_loss = 0.0\n",
        "val_correct = 0\n",
        "val_total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in val_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        val_loss += loss.item()\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        val_correct += (preds == labels).sum().item()\n",
        "        val_total += labels.size(0)\n",
        "\n",
        "    print(f\"Validation Loss: {val_loss / len(val_loader):.4f}, Accuracy: {val_correct / val_total:.4f}\")\n"
      ],
      "metadata": {
        "id": "9p4JOLQjaPTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Testing\n",
        "model.eval()\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        y_true.extend(labels.cpu().numpy())\n",
        "        y_pred.extend(preds.cpu().numpy())\n",
        "\n",
        "# Confusion matrix and classification report\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "print(\"Confusion Matrix:\\n\", cm)\n",
        "print(\"Classification Report:\\n\", classification_report(y_true, y_pred))"
      ],
      "metadata": {
        "id": "WQlHLWDkaRGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: t-SNE Visualization\n",
        "features = []\n",
        "labels_list = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        output = model(images)\n",
        "        features.append(output.cpu())\n",
        "        labels_list.append(labels)\n",
        "\n",
        "features = torch.cat(features).numpy()\n",
        "labels_list = torch.cat(labels_list).numpy()\n",
        "\n",
        "tsne = TSNE(n_components=2, random_state=42)\n",
        "reduced_features = tsne.fit_transform(features)\n",
        "\n",
        "plt.scatter(reduced_features[:, 0], reduced_features[:, 1], c=labels_list, cmap='tab10')\n",
        "plt.colorbar()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "9d-__JEdaUCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Grad-CAM Visualization\n",
        "# Fix for GradCAM target layer and arguments\n",
        "cam = GradCAM(model=model, target_layers=[model.layer4[-1]])\n",
        "\n",
        "for images, labels in test_loader:\n",
        "    images = images.to(device)\n",
        "    targets = [ClassifierOutputTarget(labels[0].item())]\n",
        "\n",
        "    try:\n",
        "        # Convert image to numpy array in [0, 1] range for visualization\n",
        "        input_image = images[0].permute(1, 2, 0).cpu().numpy()\n",
        "        input_image = (input_image - input_image.min()) / (input_image.max() - input_image.min())\n",
        "\n",
        "        grayscale_cam = cam(input_tensor=images, targets=targets)[0]\n",
        "        cam_image = show_cam_on_image(input_image, grayscale_cam, use_rgb=True)\n",
        "        plt.imshow(cam_image)\n",
        "        plt.title(f\"Grad-CAM for Class: {labels[0].item()}\")\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "    except Exception as e:\n",
        "        print(f\"Error during Grad-CAM generation: {e}\")\n",
        "    break"
      ],
      "metadata": {
        "id": "q3tGO8zoaV28"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}